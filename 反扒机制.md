## 反扒机制

- User-Agent: 模拟一个浏览器访问，是否是一个浏览器
- IP访问次数：自己的一个路由，连接外网，同是一个ip访问一个网站。需要添加延时
- Cookie: cookie的限制，需要先登陆，使用用户名和密码，用来记录登陆状态，同一ip被不同的地方访问。爬取微博，需要进行登陆，拿到cookie，微博如果进行ip访问次数，使用多个ip,使用一个cookie.
- 验证码问题：
- 代理使用:

### 反扒机制处理：

####  修改请求时的User-agent,两种方法
- 1、setting设置，在setting里面进行设置，找到“USER_AGENT=”进行设置
- 2、动态更换User-agent:在Middlware进行request的修改，修改headers，设置proxy
   通过Downloader Middleware的process_request()方法来修改：
   在middlwares.py里面添加一个RandomUserAgentMiddleware的类，如下：
   
   import random
   class RandomUserAgentMiddleware():
      def __init__(self):
          self.user_agents = [
          'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36',
           在此列表中也可以添加其他的
           ]
       def process_request(self, request, spider):
            #随机获取一个
            request.headers['User-Agent'] = random.choice(self.user_agents)
设置MiddleWare中间件，需要实现下面至少一个方法：
- process_request(self,request,spider)  处理request,实现这个类
- process_response(request,response,spider)  处理 response
- process_exception(request,exception,spider)处理异常

####  请求延时(delay)：

setting设置，Ip访问一个网站

from scrapy import cmdline
cmdline.execute("scrapy crawl xxx".split())

### 设置代理：

在process_request(self，request,spider)方法中：

request.meta['proxy'] = " "